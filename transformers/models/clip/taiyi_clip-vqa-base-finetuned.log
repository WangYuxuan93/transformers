05/08/2023 01:07:10 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
05/08/2023 01:07:10 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=120.0,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=['answer_input_ids'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/work/experiments/transformers/saves/taiyi_clip-vqa-base-finetuned/runs/May08_01-07-09_terminal-rn-kxocvxyp-0-edpaxyfs-859889c8fd-bgxm2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=120,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
optim_args=None,
output_dir=/work/experiments/transformers/saves/taiyi_clip-vqa-base-finetuned,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=True,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
resume_from_checkpoint=None,
run_name=/work/experiments/transformers/saves/taiyi_clip-vqa-base-finetuned,
save_on_each_node=False,
save_safetensors=False,
save_steps=120,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
Downloading and preparing dataset json/default to /tmp/json/default-e1349fcecd22a2f4/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...
Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 3/3 [00:00<00:00, 22836.50it/s]
Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 421.00it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 30903 examples [00:00, 140988.11 examples/s]                                                                    Generating validation split: 0 examples [00:00, ? examples/s]                                                             Generating test split: 0 examples [00:00, ? examples/s]                                                       Dataset json downloaded and prepared to /tmp/json/default-e1349fcecd22a2f4/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 806.08it/s]
[INFO|tokenization_utils_base.py:1842] 2023-05-08 01:07:21,272 >> loading file vocab.txt
[INFO|tokenization_utils_base.py:1842] 2023-05-08 01:07:21,273 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:1842] 2023-05-08 01:07:21,273 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1842] 2023-05-08 01:07:21,273 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1842] 2023-05-08 01:07:21,273 >> loading file tokenizer_config.json
[INFO|image_processing_utils.py:337] 2023-05-08 01:07:21,283 >> loading configuration file /work/models/taiyi-clip-roberta/preprocessor_config.json
[INFO|image_processing_utils.py:389] 2023-05-08 01:07:21,288 >> Image processor CLIPImageProcessor {
  "crop_size": {
    "height": 224,
    "width": 224
  },
  "do_center_crop": true,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "CLIPImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "processor_class": "VisionTextDualEncoderProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "shortest_edge": 224
  }
}

[INFO|configuration_utils.py:710] 2023-05-08 01:07:21,289 >> loading configuration file /work/models/taiyi-clip-roberta/config.json
[WARNING|configuration_utils.py:592] 2023-05-08 01:07:21,289 >> You are using a model of type vision-text-dual-encoder to instantiate a model of type clip. This is not supported for all configurations of models and can yield errors.
[INFO|configuration_utils.py:768] 2023-05-08 01:07:21,293 >> Model config CLIPConfig {
  "_commit_hash": null,
  "architectures": [
    "VisionTextDualEncoderModel"
  ],
  "initializer_factor": 1.0,
  "logit_scale_init_value": 2.6592,
  "model_type": "clip",
  "projection_dim": 512,
  "text_config": {
    "_name_or_path": "/work/models/Taiyi-CLIP-Roberta-102M-Chinese",
    "add_cross_attention": false,
    "architectures": [
      "BertForSequenceClassification"
    ],
    "attention_dropout": 0.0,
    "attention_probs_dropout_prob": 0.1,
    "bad_words_ids": null,
    "begin_suppress_tokens": null,
    "bos_token_id": 0,
    "chunk_size_feed_forward": 0,
    "classifier_dropout": null,
    "cross_attention_hidden_size": null,
    "decoder_start_token_id": null,
    "directionality": "bidi",
    "diversity_penalty": 0.0,
    "do_sample": false,
    "early_stopping": false,
    "encoder_no_repeat_ngram_size": 0,
    "eos_token_id": 2,
    "exponential_decay_length_penalty": null,
    "finetuning_task": null,
    "forced_bos_token_id": null,
    "forced_eos_token_id": null,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "id2label": {
      "0": "LABEL_0",
      "1": "LABEL_1",
      "2": "LABEL_2",
      "3": "LABEL_3",
      "4": "LABEL_4",
      "5": "LABEL_5",
      "6": "LABEL_6",
      "7": "LABEL_7",
      "8": "LABEL_8",
      "9": "LABEL_9",
      "10": "LABEL_10",
      "11": "LABEL_11",
      "12": "LABEL_12",
      "13": "LABEL_13",
      "14": "LABEL_14",
      "15": "LABEL_15",
      "16": "LABEL_16",
      "17": "LABEL_17",
      "18": "LABEL_18",
      "19": "LABEL_19",
      "20": "LABEL_20",
      "21": "LABEL_21",
      "22": "LABEL_22",
      "23": "LABEL_23",
      "24": "LABEL_24",
      "25": "LABEL_25",
      "26": "LABEL_26",
      "27": "LABEL_27",
      "28": "LABEL_28",
      "29": "LABEL_29",
      "30": "LABEL_30",
      "31": "LABEL_31",
      "32": "LABEL_32",
      "33": "LABEL_33",
      "34": "LABEL_34",
      "35": "LABEL_35",
      "36": "LABEL_36",
      "37": "LABEL_37",
      "38": "LABEL_38",
      "39": "LABEL_39",
      "40": "LABEL_40",
      "41": "LABEL_41",
      "42": "LABEL_42",
      "43": "LABEL_43",
      "44": "LABEL_44",
      "45": "LABEL_45",
      "46": "LABEL_46",
      "47": "LABEL_47",
      "48": "LABEL_48",
      "49": "LABEL_49",
      "50": "LABEL_50",
      "51": "LABEL_51",
      "52": "LABEL_52",
      "53": "LABEL_53",
      "54": "LABEL_54",
      "55": "LABEL_55",
      "56": "LABEL_56",
      "57": "LABEL_57",
      "58": "LABEL_58",
      "59": "LABEL_59",
      "60": "LABEL_60",
      "61": "LABEL_61",
      "62": "LABEL_62",
      "63": "LABEL_63",
      "64": "LABEL_64",
      "65": "LABEL_65",
      "66": "LABEL_66",
      "67": "LABEL_67",
      "68": "LABEL_68",
      "69": "LABEL_69",
      "70": "LABEL_70",
      "71": "LABEL_71",
      "72": "LABEL_72",
      "73": "LABEL_73",
      "74": "LABEL_74",
      "75": "LABEL_75",
      "76": "LABEL_76",
      "77": "LABEL_77",
      "78": "LABEL_78",
      "79": "LABEL_79",
      "80": "LABEL_80",
      "81": "LABEL_81",
      "82": "LABEL_82",
      "83": "LABEL_83",
      "84": "LABEL_84",
      "85": "LABEL_85",
      "86": "LABEL_86",
      "87": "LABEL_87",
      "88": "LABEL_88",
      "89": "LABEL_89",
      "90": "LABEL_90",
      "91": "LABEL_91",
      "92": "LABEL_92",
      "93": "LABEL_93",
      "94": "LABEL_94",
      "95": "LABEL_95",
      "96": "LABEL_96",
      "97": "LABEL_97",
      "98": "LABEL_98",
      "99": "LABEL_99",
      "100": "LABEL_100",
      "101": "LABEL_101",
      "102": "LABEL_102",
      "103": "LABEL_103",
      "104": "LABEL_104",
      "105": "LABEL_105",
      "106": "LABEL_106",
      "107": "LABEL_107",
      "108": "LABEL_108",
      "109": "LABEL_109",
      "110": "LABEL_110",
      "111": "LABEL_111",
      "112": "LABEL_112",
      "113": "LABEL_113",
      "114": "LABEL_114",
      "115": "LABEL_115",
      "116": "LABEL_116",
      "117": "LABEL_117",
      "118": "LABEL_118",
      "119": "LABEL_119",
      "120": "LABEL_120",
      "121": "LABEL_121",
      "122": "LABEL_122",
      "123": "LABEL_123",
      "124": "LABEL_124",
      "125": "LABEL_125",
      "126": "LABEL_126",
      "127": "LABEL_127",
      "128": "LABEL_128",
      "129": "LABEL_129",
      "130": "LABEL_130",
      "131": "LABEL_131",
      "132": "LABEL_132",
      "133": "LABEL_133",
      "134": "LABEL_134",
      "135": "LABEL_135",
      "136": "LABEL_136",
      "137": "LABEL_137",
      "138": "LABEL_138",
      "139": "LABEL_139",
      "140": "LABEL_140",
      "141": "LABEL_141",
      "142": "LABEL_142",
      "143": "LABEL_143",
      "144": "LABEL_144",
      "145": "LABEL_145",
      "146": "LABEL_146",
      "147": "LABEL_147",
      "148": "LABEL_148",
      "149": "LABEL_149",
      "150": "LABEL_150",
      "151": "LABEL_151",
      "152": "LABEL_152",
      "153": "LABEL_153",
      "154": "LABEL_154",
      "155": "LABEL_155",
      "156": "LABEL_156",
      "157": "LABEL_157",
      "158": "LABEL_158",
      "159": "LABEL_159",
      "160": "LABEL_160",
      "161": "LABEL_161",
      "162": "LABEL_162",
      "163": "LABEL_163",
      "164": "LABEL_164",
      "165": "LABEL_165",
      "166": "LABEL_166",
      "167": "LABEL_167",
      "168": "LABEL_168",
      "169": "LABEL_169",
      "170": "LABEL_170",
      "171": "LABEL_171",
      "172": "LABEL_172",
      "173": "LABEL_173",
      "174": "LABEL_174",
      "175": "LABEL_175",
      "176": "LABEL_176",
      "177": "LABEL_177",
      "178": "LABEL_178",
      "179": "LABEL_179",
      "180": "LABEL_180",
      "181": "LABEL_181",
      "182": "LABEL_182",
      "183": "LABEL_183",
      "184": "LABEL_184",
      "185": "LABEL_185",
      "186": "LABEL_186",
      "187": "LABEL_187",
      "188": "LABEL_188",
      "189": "LABEL_189",
      "190": "LABEL_190",
      "191": "LABEL_191",
      "192": "LABEL_192",
      "193": "LABEL_193",
      "194": "LABEL_194",
      "195": "LABEL_195",
      "196": "LABEL_196",
      "197": "LABEL_197",
      "198": "LABEL_198",
      "199": "LABEL_199",
      "200": "LABEL_200",
      "201": "LABEL_201",
      "202": "LABEL_202",
      "203": "LABEL_203",
      "204": "LABEL_204",
      "205": "LABEL_205",
      "206": "LABEL_206",
      "207": "LABEL_207",
      "208": "LABEL_208",
      "209": "LABEL_209",
      "210": "LABEL_210",
      "211": "LABEL_211",
      "212": "LABEL_212",
      "213": "LABEL_213",
      "214": "LABEL_214",
      "215": "LABEL_215",
      "216": "LABEL_216",
      "217": "LABEL_217",
      "218": "LABEL_218",
      "219": "LABEL_219",
      "220": "LABEL_220",
      "221": "LABEL_221",
      "222": "LABEL_222",
      "223": "LABEL_223",
      "224": "LABEL_224",
      "225": "LABEL_225",
      "226": "LABEL_226",
      "227": "LABEL_227",
      "228": "LABEL_228",
      "229": "LABEL_229",
      "230": "LABEL_230",
      "231": "LABEL_231",
      "232": "LABEL_232",
      "233": "LABEL_233",
      "234": "LABEL_234",
      "235": "LABEL_235",
      "236": "LABEL_236",
      "237": "LABEL_237",
      "238": "LABEL_238",
      "239": "LABEL_239",
      "240": "LABEL_240",
      "241": "LABEL_241",
      "242": "LABEL_242",
      "243": "LABEL_243",
      "244": "LABEL_244",
      "245": "LABEL_245",
      "246": "LABEL_246",
      "247": "LABEL_247",
      "248": "LABEL_248",
      "249": "LABEL_249",
      "250": "LABEL_250",
      "251": "LABEL_251",
      "252": "LABEL_252",
      "253": "LABEL_253",
      "254": "LABEL_254",
      "255": "LABEL_255",
      "256": "LABEL_256",
      "257": "LABEL_257",
      "258": "LABEL_258",
      "259": "LABEL_259",
      "260": "LABEL_260",
      "261": "LABEL_261",
      "262": "LABEL_262",
      "263": "LABEL_263",
      "264": "LABEL_264",
      "265": "LABEL_265",
      "266": "LABEL_266",
      "267": "LABEL_267",
      "268": "LABEL_268",
      "269": "LABEL_269",
      "270": "LABEL_270",
      "271": "LABEL_271",
      "272": "LABEL_272",
      "273": "LABEL_273",
      "274": "LABEL_274",
      "275": "LABEL_275",
      "276": "LABEL_276",
      "277": "LABEL_277",
      "278": "LABEL_278",
      "279": "LABEL_279",
      "280": "LABEL_280",
      "281": "LABEL_281",
      "282": "LABEL_282",
      "283": "LABEL_283",
      "284": "LABEL_284",
      "285": "LABEL_285",
      "286": "LABEL_286",
      "287": "LABEL_287",
      "288": "LABEL_288",
      "289": "LABEL_289",
      "290": "LABEL_290",
      "291": "LABEL_291",
      "292": "LABEL_292",
      "293": "LABEL_293",
      "294": "LABEL_294",
      "295": "LABEL_295",
      "296": "LABEL_296",
      "297": "LABEL_297",
      "298": "LABEL_298",
      "299": "LABEL_299",
      "300": "LABEL_300",
      "301": "LABEL_301",
      "302": "LABEL_302",
      "303": "LABEL_303",
      "304": "LABEL_304",
      "305": "LABEL_305",
      "306": "LABEL_306",
      "307": "LABEL_307",
      "308": "LABEL_308",
      "309": "LABEL_309",
      "310": "LABEL_310",
      "311": "LABEL_311",
      "312": "LABEL_312",
      "313": "LABEL_313",
      "314": "LABEL_314",
      "315": "LABEL_315",
      "316": "LABEL_316",
      "317": "LABEL_317",
      "318": "LABEL_318",
      "319": "LABEL_319",
      "320": "LABEL_320",
      "321": "LABEL_321",
      "322": "LABEL_322",
      "323": "LABEL_323",
      "324": "LABEL_324",
      "325": "LABEL_325",
      "326": "LABEL_326",
      "327": "LABEL_327",
      "328": "LABEL_328",
      "329": "LABEL_329",
      "330": "LABEL_330",
      "331": "LABEL_331",
      "332": "LABEL_332",
      "333": "LABEL_333",
      "334": "LABEL_334",
      "335": "LABEL_335",
      "336": "LABEL_336",
      "337": "LABEL_337",
      "338": "LABEL_338",
      "339": "LABEL_339",
      "340": "LABEL_340",
      "341": "LABEL_341",
      "342": "LABEL_342",
      "343": "LABEL_343",
      "344": "LABEL_344",
      "345": "LABEL_345",
      "346": "LABEL_346",
      "347": "LABEL_347",
      "348": "LABEL_348",
      "349": "LABEL_349",
      "350": "LABEL_350",
      "351": "LABEL_351",
      "352": "LABEL_352",
      "353": "LABEL_353",
      "354": "LABEL_354",
      "355": "LABEL_355",
      "356": "LABEL_356",
      "357": "LABEL_357",
      "358": "LABEL_358",
      "359": "LABEL_359",
      "360": "LABEL_360",
      "361": "LABEL_361",
      "362": "LABEL_362",
      "363": "LABEL_363",
      "364": "LABEL_364",
      "365": "LABEL_365",
      "366": "LABEL_366",
      "367": "LABEL_367",
      "368": "LABEL_368",
      "369": "LABEL_369",
      "370": "LABEL_370",
      "371": "LABEL_371",
      "372": "LABEL_372",
      "373": "LABEL_373",
      "374": "LABEL_374",
      "375": "LABEL_375",
      "376": "LABEL_376",
      "377": "LABEL_377",
      "378": "LABEL_378",
      "379": "LABEL_379",
      "380": "LABEL_380",
      "381": "LABEL_381",
      "382": "LABEL_382",
      "383": "LABEL_383",
      "384": "LABEL_384",
      "385": "LABEL_385",
      "386": "LABEL_386",
      "387": "LABEL_387",
      "388": "LABEL_388",
      "389": "LABEL_389",
      "390": "LABEL_390",
      "391": "LABEL_391",
      "392": "LABEL_392",
      "393": "LABEL_393",
      "394": "LABEL_394",
      "395": "LABEL_395",
      "396": "LABEL_396",
      "397": "LABEL_397",
      "398": "LABEL_398",
      "399": "LABEL_399",
      "400": "LABEL_400",
      "401": "LABEL_401",
      "402": "LABEL_402",
      "403": "LABEL_403",
      "404": "LABEL_404",
      "405": "LABEL_405",
      "406": "LABEL_406",
      "407": "LABEL_407",
      "408": "LABEL_408",
      "409": "LABEL_409",
      "410": "LABEL_410",
      "411": "LABEL_411",
      "412": "LABEL_412",
      "413": "LABEL_413",
      "414": "LABEL_414",
      "415": "LABEL_415",
      "416": "LABEL_416",
      "417": "LABEL_417",
      "418": "LABEL_418",
      "419": "LABEL_419",
      "420": "LABEL_420",
      "421": "LABEL_421",
      "422": "LABEL_422",
      "423": "LABEL_423",
      "424": "LABEL_424",
      "425": "LABEL_425",
      "426": "LABEL_426",
      "427": "LABEL_427",
      "428": "LABEL_428",
      "429": "LABEL_429",
      "430": "LABEL_430",
      "431": "LABEL_431",
      "432": "LABEL_432",
      "433": "LABEL_433",
      "434": "LABEL_434",
      "435": "LABEL_435",
      "436": "LABEL_436",
      "437": "LABEL_437",
      "438": "LABEL_438",
      "439": "LABEL_439",
      "440": "LABEL_440",
      "441": "LABEL_441",
      "442": "LABEL_442",
      "443": "LABEL_443",
      "444": "LABEL_444",
      "445": "LABEL_445",
      "446": "LABEL_446",
      "447": "LABEL_447",
      "448": "LABEL_448",
      "449": "LABEL_449",
      "450": "LABEL_450",
      "451": "LABEL_451",
      "452": "LABEL_452",
      "453": "LABEL_453",
      "454": "LABEL_454",
      "455": "LABEL_455",
      "456": "LABEL_456",
      "457": "LABEL_457",
      "458": "LABEL_458",
      "459": "LABEL_459",
      "460": "LABEL_460",
      "461": "LABEL_461",
      "462": "LABEL_462",
      "463": "LABEL_463",
      "464": "LABEL_464",
      "465": "LABEL_465",
      "466": "LABEL_466",
      "467": "LABEL_467",
      "468": "LABEL_468",
      "469": "LABEL_469",
      "470": "LABEL_470",
      "471": "LABEL_471",
      "472": "LABEL_472",
      "473": "LABEL_473",
      "474": "LABEL_474",
      "475": "LABEL_475",
      "476": "LABEL_476",
      "477": "LABEL_477",
      "478": "LABEL_478",
      "479": "LABEL_479",
      "480": "LABEL_480",
      "481": "LABEL_481",
      "482": "LABEL_482",
      "483": "LABEL_483",
      "484": "LABEL_484",
      "485": "LABEL_485",
      "486": "LABEL_486",
      "487": "LABEL_487",
      "488": "LABEL_488",
      "489": "LABEL_489",
      "490": "LABEL_490",
      "491": "LABEL_491",
      "492": "LABEL_492",
      "493": "LABEL_493",
      "494": "LABEL_494",
      "495": "LABEL_495",
      "496": "LABEL_496",
      "497": "LABEL_497",
      "498": "LABEL_498",
      "499": "LABEL_499",
      "500": "LABEL_500",
      "501": "LABEL_501",
      "502": "LABEL_502",
      "503": "LABEL_503",
      "504": "LABEL_504",
      "505": "LABEL_505",
      "506": "LABEL_506",
      "507": "LABEL_507",
      "508": "LABEL_508",
      "509": "LABEL_509",
      "510": "LABEL_510",
      "511": "LABEL_511"
    },
    "initializer_factor": 1.0,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "is_decoder": false,
    "is_encoder_decoder": false,
    "label2id": {
      "LABEL_0": 0,
      "LABEL_1": 1,
      "LABEL_10": 10,
      "LABEL_100": 100,
      "LABEL_101": 101,
      "LABEL_102": 102,
      "LABEL_103": 103,
      "LABEL_104": 104,
      "LABEL_105": 105,
      "LABEL_106": 106,
      "LABEL_107": 107,
      "LABEL_108": 108,
      "LABEL_109": 109,
      "LABEL_11": 11,
      "LABEL_110": 110,
      "LABEL_111": 111,
      "LABEL_112": 112,
      "LABEL_113": 113,
      "LABEL_114": 114,
      "LABEL_115": 115,
      "LABEL_116": 116,
      "LABEL_117": 117,
      "LABEL_118": 118,
      "LABEL_119": 119,
      "LABEL_12": 12,
      "LABEL_120": 120,
      "LABEL_121": 121,
      "LABEL_122": 122,
      "LABEL_123": 123,
      "LABEL_124": 124,
      "LABEL_125": 125,
      "LABEL_126": 126,
      "LABEL_127": 127,
      "LABEL_128": 128,
      "LABEL_129": 129,
      "LABEL_13": 13,
      "LABEL_130": 130,
      "LABEL_131": 131,
      "LABEL_132": 132,
      "LABEL_133": 133,
      "LABEL_134": 134,
      "LABEL_135": 135,
      "LABEL_136": 136,
      "LABEL_137": 137,
      "LABEL_138": 138,
      "LABEL_139": 139,
      "LABEL_14": 14,
      "LABEL_140": 140,
      "LABEL_141": 141,
      "LABEL_142": 142,
      "LABEL_143": 143,
      "LABEL_144": 144,
      "LABEL_145": 145,
      "LABEL_146": 146,
      "LABEL_147": 147,
      "LABEL_148": 148,
      "LABEL_149": 149,
      "LABEL_15": 15,
      "LABEL_150": 150,
      "LABEL_151": 151,
      "LABEL_152": 152,
      "LABEL_153": 153,
      "LABEL_154": 154,
      "LABEL_155": 155,
      "LABEL_156": 156,
      "LABEL_157": 157,
      "LABEL_158": 158,
      "LABEL_159": 159,
      "LABEL_16": 16,
      "LABEL_160": 160,
      "LABEL_161": 161,
      "LABEL_162": 162,
      "LABEL_163": 163,
      "LABEL_164": 164,
      "LABEL_165": 165,
      "LABEL_166": 166,
      "LABEL_167": 167,
      "LABEL_168": 168,
      "LABEL_169": 169,
      "LABEL_17": 17,
      "LABEL_170": 170,
      "LABEL_171": 171,
      "LABEL_172": 172,
      "LABEL_173": 173,
      "LABEL_174": 174,
      "LABEL_175": 175,
      "LABEL_176": 176,
      "LABEL_177": 177,
      "LABEL_178": 178,
      "LABEL_179": 179,
      "LABEL_18": 18,
      "LABEL_180": 180,
      "LABEL_181": 181,
      "LABEL_182": 182,
      "LABEL_183": 183,
      "LABEL_184": 184,
      "LABEL_185": 185,
      "LABEL_186": 186,
      "LABEL_187": 187,
      "LABEL_188": 188,
      "LABEL_189": 189,
      "LABEL_19": 19,
      "LABEL_190": 190,
      "LABEL_191": 191,
      "LABEL_192": 192,
      "LABEL_193": 193,
      "LABEL_194": 194,
      "LABEL_195": 195,
      "LABEL_196": 196,
      "LABEL_197": 197,
      "LABEL_198": 198,
      "LABEL_199": 199,
      "LABEL_2": 2,
      "LABEL_20": 20,
      "LABEL_200": 200,
      "LABEL_201": 201,
      "LABEL_202": 202,
      "LABEL_203": 203,
      "LABEL_204": 204,
      "LABEL_205": 205,
      "LABEL_206": 206,
      "LABEL_207": 207,
      "LABEL_208": 208,
      "LABEL_209": 209,
      "LABEL_21": 21,
      "LABEL_210": 210,
      "LABEL_211": 211,
      "LABEL_212": 212,
      "LABEL_213": 213,
      "LABEL_214": 214,
      "LABEL_215": 215,
      "LABEL_216": 216,
      "LABEL_217": 217,
      "LABEL_218": 218,
      "LABEL_219": 219,
      "LABEL_22": 22,
      "LABEL_220": 220,
      "LABEL_221": 221,
      "LABEL_222": 222,
      "LABEL_223": 223,
      "LABEL_224": 224,
      "LABEL_225": 225,
      "LABEL_226": 226,
      "LABEL_227": 227,
      "LABEL_228": 228,
      "LABEL_229": 229,
      "LABEL_23": 23,
      "LABEL_230": 230,
      "LABEL_231": 231,
      "LABEL_232": 232,
      "LABEL_233": 233,
      "LABEL_234": 234,
      "LABEL_235": 235,
      "LABEL_236": 236,
      "LABEL_237": 237,
      "LABEL_238": 238,
      "LABEL_239": 239,
      "LABEL_24": 24,
      "LABEL_240": 240,
      "LABEL_241": 241,
      "LABEL_242": 242,
      "LABEL_243": 243,
      "LABEL_244": 244,
      "LABEL_245": 245,
      "LABEL_246": 246,
      "LABEL_247": 247,
      "LABEL_248": 248,
      "LABEL_249": 249,
      "LABEL_25": 25,
      "LABEL_250": 250,
      "LABEL_251": 251,
      "LABEL_252": 252,
      "LABEL_253": 253,
      "LABEL_254": 254,
      "LABEL_255": 255,
      "LABEL_256": 256,
      "LABEL_257": 257,
      "LABEL_258": 258,
      "LABEL_259": 259,
      "LABEL_26": 26,
      "LABEL_260": 260,
      "LABEL_261": 261,
      "LABEL_262": 262,
      "LABEL_263": 263,
      "LABEL_264": 264,
      "LABEL_265": 265,
      "LABEL_266": 266,
      "LABEL_267": 267,
      "LABEL_268": 268,
      "LABEL_269": 269,
      "LABEL_27": 27,
      "LABEL_270": 270,
      "LABEL_271": 271,
      "LABEL_272": 272,
      "LABEL_273": 273,
      "LABEL_274": 274,
      "LABEL_275": 275,
      "LABEL_276": 276,
      "LABEL_277": 277,
      "LABEL_278": 278,
      "LABEL_279": 279,
      "LABEL_28": 28,
      "LABEL_280": 280,
      "LABEL_281": 281,
      "LABEL_282": 282,
      "LABEL_283": 283,
      "LABEL_284": 284,
      "LABEL_285": 285,
      "LABEL_286": 286,
      "LABEL_287": 287,
      "LABEL_288": 288,
      "LABEL_289": 289,
      "LABEL_29": 29,
      "LABEL_290": 290,
      "LABEL_291": 291,
      "LABEL_292": 292,
      "LABEL_293": 293,
      "LABEL_294": 294,
      "LABEL_295": 295,
      "LABEL_296": 296,
      "LABEL_297": 297,
      "LABEL_298": 298,
      "LABEL_299": 299,
      "LABEL_3": 3,
      "LABEL_30": 30,
      "LABEL_300": 300,
      "LABEL_301": 301,
      "LABEL_302": 302,
      "LABEL_303": 303,
      "LABEL_304": 304,
      "LABEL_305": 305,
      "LABEL_306": 306,
      "LABEL_307": 307,
      "LABEL_308": 308,
      "LABEL_309": 309,
      "LABEL_31": 31,
      "LABEL_310": 310,
      "LABEL_311": 311,
      "LABEL_312": 312,
      "LABEL_313": 313,
      "LABEL_314": 314,
      "LABEL_315": 315,
      "LABEL_316": 316,
      "LABEL_317": 317,
      "LABEL_318": 318,
      "LABEL_319": 319,
      "LABEL_32": 32,
      "LABEL_320": 320,
      "LABEL_321": 321,
      "LABEL_322": 322,
      "LABEL_323": 323,
      "LABEL_324": 324,
      "LABEL_325": 325,
      "LABEL_326": 326,
      "LABEL_327": 327,
      "LABEL_328": 328,
      "LABEL_329": 329,
      "LABEL_33": 33,
      "LABEL_330": 330,
      "LABEL_331": 331,
      "LABEL_332": 332,
      "LABEL_333": 333,
      "LABEL_334": 334,
      "LABEL_335": 335,
      "LABEL_336": 336,
      "LABEL_337": 337,
      "LABEL_338": 338,
      "LABEL_339": 339,
      "LABEL_34": 34,
      "LABEL_340": 340,
      "LABEL_341": 341,
      "LABEL_342": 342,
      "LABEL_343": 343,
      "LABEL_344": 344,
      "LABEL_345": 345,
      "LABEL_346": 346,
      "LABEL_347": 347,
      "LABEL_348": 348,
      "LABEL_349": 349,
      "LABEL_35": 35,
      "LABEL_350": 350,
      "LABEL_351": 351,
      "LABEL_352": 352,
      "LABEL_353": 353,
      "LABEL_354": 354,
      "LABEL_355": 355,
      "LABEL_356": 356,
      "LABEL_357": 357,
      "LABEL_358": 358,
      "LABEL_359": 359,
      "LABEL_36": 36,
      "LABEL_360": 360,
      "LABEL_361": 361,
      "LABEL_362": 362,
      "LABEL_363": 363,
      "LABEL_364": 364,
      "LABEL_365": 365,
      "LABEL_366": 366,
      "LABEL_367": 367,
      "LABEL_368": 368,
      "LABEL_369": 369,
      "LABEL_37": 37,
      "LABEL_370": 370,
      "LABEL_371": 371,
      "LABEL_372": 372,
      "LABEL_373": 373,
      "LABEL_374": 374,
      "LABEL_375": 375,
      "LABEL_376": 376,
      "LABEL_377": 377,
      "LABEL_378": 378,
      "LABEL_379": 379,
      "LABEL_38": 38,
      "LABEL_380": 380,
      "LABEL_381": 381,
      "LABEL_382": 382,
      "LABEL_383": 383,
      "LABEL_384": 384,
      "LABEL_385": 385,
      "LABEL_386": 386,
      "LABEL_387": 387,
      "LABEL_388": 388,
      "LABEL_389": 389,
      "LABEL_39": 39,
      "LABEL_390": 390,
      "LABEL_391": 391,
      "LABEL_392": 392,
      "LABEL_393": 393,
      "LABEL_394": 394,
      "LABEL_395": 395,
      "LABEL_396": 396,
      "LABEL_397": 397,
      "LABEL_398": 398,
      "LABEL_399": 399,
      "LABEL_4": 4,
      "LABEL_40": 40,
      "LABEL_400": 400,
      "LABEL_401": 401,
      "LABEL_402": 402,
      "LABEL_403": 403,
      "LABEL_404": 404,
      "LABEL_405": 405,
      "LABEL_406": 406,
      "LABEL_407": 407,
      "LABEL_408": 408,
      "LABEL_409": 409,
      "LABEL_41": 41,
      "LABEL_410": 410,
      "LABEL_411": 411,
      "LABEL_412": 412,
      "LABEL_413": 413,
      "LABEL_414": 414,
      "LABEL_415": 415,
      "LABEL_416": 416,
      "LABEL_417": 417,
      "LABEL_418": 418,
      "LABEL_419": 419,
      "LABEL_42": 42,
      "LABEL_420": 420,
      "LABEL_421": 421,
      "LABEL_422": 422,
      "LABEL_423": 423,
      "LABEL_424": 424,
      "LABEL_425": 425,
      "LABEL_426": 426,
      "LABEL_427": 427,
      "LABEL_428": 428,
      "LABEL_429": 429,
      "LABEL_43": 43,
      "LABEL_430": 430,
      "LABEL_431": 431,
      "LABEL_432": 432,
      "LABEL_433": 433,
      "LABEL_434": 434,
      "LABEL_435": 435,
      "LABEL_436": 436,
      "LABEL_437": 437,
      "LABEL_438": 438,
      "LABEL_439": 439,
      "LABEL_44": 44,
      "LABEL_440": 440,
      "LABEL_441": 441,
      "LABEL_442": 442,
      "LABEL_443": 443,
      "LABEL_444": 444,
      "LABEL_445": 445,
      "LABEL_446": 446,
      "LABEL_447": 447,
      "LABEL_448": 448,
      "LABEL_449": 449,
      "LABEL_45": 45,
      "LABEL_450": 450,
      "LABEL_451": 451,
      "LABEL_452": 452,
      "LABEL_453": 453,
      "LABEL_454": 454,
      "LABEL_455": 455,
      "LABEL_456": 456,
      "LABEL_457": 457,
      "LABEL_458": 458,
      "LABEL_459": 459,
      "LABEL_46": 46,
      "LABEL_460": 460,
      "LABEL_461": 461,
      "LABEL_462": 462,
      "LABEL_463": 463,
      "LABEL_464": 464,
      "LABEL_465": 465,
      "LABEL_466": 466,
      "LABEL_467": 467,
      "LABEL_468": 468,
      "LABEL_469": 469,
      "LABEL_47": 47,
      "LABEL_470": 470,
      "LABEL_471": 471,
      "LABEL_472": 472,
      "LABEL_473": 473,
      "LABEL_474": 474,
      "LABEL_475": 475,
      "LABEL_476": 476,
      "LABEL_477": 477,
      "LABEL_478": 478,
      "LABEL_479": 479,
      "LABEL_48": 48,
      "LABEL_480": 480,
      "LABEL_481": 481,
      "LABEL_482": 482,
      "LABEL_483": 483,
      "LABEL_484": 484,
      "LABEL_485": 485,
      "LABEL_486": 486,
      "LABEL_487": 487,
      "LABEL_488": 488,
      "LABEL_489": 489,
      "LABEL_49": 49,
      "LABEL_490": 490,
      "LABEL_491": 491,
      "LABEL_492": 492,
      "LABEL_493": 493,
      "LABEL_494": 494,
      "LABEL_495": 495,
      "LABEL_496": 496,
      "LABEL_497": 497,
      "LABEL_498": 498,
      "LABEL_499": 499,
      "LABEL_5": 5,
      "LABEL_50": 50,
      "LABEL_500": 500,
      "LABEL_501": 501,
      "LABEL_502": 502,
      "LABEL_503": 503,
      "LABEL_504": 504,
      "LABEL_505": 505,
      "LABEL_506": 506,
      "LABEL_507": 507,
      "LABEL_508": 508,
      "LABEL_509": 509,
      "LABEL_51": 51,
      "LABEL_510": 510,
      "LABEL_511": 511,
      "LABEL_52": 52,
      "LABEL_53": 53,
      "LABEL_54": 54,
      "LABEL_55": 55,
      "LABEL_56": 56,
      "LABEL_57": 57,
      "LABEL_58": 58,
      "LABEL_59": 59,
      "LABEL_6": 6,
      "LABEL_60": 60,
      "LABEL_61": 61,
      "LABEL_62": 62,
      "LABEL_63": 63,
      "LABEL_64": 64,
      "LABEL_65": 65,
      "LABEL_66": 66,
      "LABEL_67": 67,
      "LABEL_68": 68,
      "LABEL_69": 69,
      "LABEL_7": 7,
      "LABEL_70": 70,
      "LABEL_71": 71,
      "LABEL_72": 72,
      "LABEL_73": 73,
      "LABEL_74": 74,
      "LABEL_75": 75,
      "LABEL_76": 76,
      "LABEL_77": 77,
      "LABEL_78": 78,
      "LABEL_79": 79,
      "LABEL_8": 8,
      "LABEL_80": 80,
      "LABEL_81": 81,
      "LABEL_82": 82,
      "LABEL_83": 83,
      "LABEL_84": 84,
      "LABEL_85": 85,
      "LABEL_86": 86,
      "LABEL_87": 87,
      "LABEL_88": 88,
      "LABEL_89": 89,
      "LABEL_9": 9,
      "LABEL_90": 90,
      "LABEL_91": 91,
      "LABEL_92": 92,
      "LABEL_93": 93,
      "LABEL_94": 94,
      "LABEL_95": 95,
      "LABEL_96": 96,
      "LABEL_97": 97,
      "LABEL_98": 98,
      "LABEL_99": 99
    },
    "layer_norm_eps": 1e-12,
    "length_penalty": 1.0,
    "max_length": 20,
    "max_position_embeddings": 512,
    "min_length": 0,
    "model_type": "clip_text_model",
    "no_repeat_ngram_size": 0,
    "num_attention_heads": 12,
    "num_beam_groups": 1,
    "num_beams": 1,
    "num_hidden_layers": 12,
    "num_return_sequences": 1,
    "output_attentions": false,
    "output_hidden_states": false,
    "output_past": true,
    "output_scores": false,
    "pad_token_id": 0,
    "pooler_fc_size": 768,
    "pooler_num_attention_heads": 12,
    "pooler_num_fc_layers": 3,
    "pooler_size_per_head": 128,
    "pooler_type": "first_token_transform",
    "position_embedding_type": "absolute",
    "prefix": null,
    "problem_type": null,
    "projection_dim": 512,
    "pruned_heads": {},
    "remove_invalid_values": false,
    "repetition_penalty": 1.0,
    "return_dict": true,
    "return_dict_in_generate": false,
    "sep_token_id": null,
    "suppress_tokens": null,
    "task_specific_params": null,
    "temperature": 1.0,
    "tf_legacy_loss": false,
    "tie_encoder_decoder": false,
    "tie_word_embeddings": true,
    "tokenizer_class": null,
    "top_k": 50,
    "top_p": 1.0,
    "torch_dtype": "float32",
    "torchscript": false,
    "transformers_version": "4.31.0.dev0",
    "type_vocab_size": 2,
    "typical_p": 1.0,
    "use_bfloat16": false,
    "use_cache": true,
    "vocab_size": 21128
  },
  "torch_dtype": "float32",
  "transformers_version": null,
  "vision_config": {
    "_name_or_path": "/work/models/clip-vit-base-patch32",
    "add_cross_attention": false,
    "architectures": null,
    "attention_dropout": 0.0,
    "bad_words_ids": null,
    "begin_suppress_tokens": null,
    "bos_token_id": null,
    "chunk_size_feed_forward": 0,
    "cross_attention_hidden_size": null,
    "decoder_start_token_id": null,
    "diversity_penalty": 0.0,
    "do_sample": false,
    "dropout": 0.0,
    "early_stopping": false,
    "encoder_no_repeat_ngram_size": 0,
    "eos_token_id": null,
    "exponential_decay_length_penalty": null,
    "finetuning_task": null,
    "forced_bos_token_id": null,
    "forced_eos_token_id": null,
    "hidden_act": "quick_gelu",
    "hidden_size": 768,
    "id2label": {
      "0": "LABEL_0",
      "1": "LABEL_1"
    },
    "image_size": 224,
    "initializer_factor": 1.0,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "is_decoder": false,
    "is_encoder_decoder": false,
    "label2id": {
      "LABEL_0": 0,
      "LABEL_1": 1
    },
    "layer_norm_eps": 1e-05,
    "length_penalty": 1.0,
    "max_length": 20,
    "min_length": 0,
    "model_type": "clip_vision_model",
    "no_repeat_ngram_size": 0,
    "num_attention_heads": 12,
    "num_beam_groups": 1,
    "num_beams": 1,
    "num_channels": 3,
    "num_hidden_layers": 12,
    "num_return_sequences": 1,
    "output_attentions": false,
    "output_hidden_states": false,
    "output_scores": false,
    "pad_token_id": null,
    "patch_size": 32,
    "prefix": null,
    "problem_type": null,
    "projection_dim": 512,
    "pruned_heads": {},
    "remove_invalid_values": false,
    "repetition_penalty": 1.0,
    "return_dict": true,
    "return_dict_in_generate": false,
    "sep_token_id": null,
    "suppress_tokens": null,
    "task_specific_params": null,
    "temperature": 1.0,
    "tf_legacy_loss": false,
    "tie_encoder_decoder": false,
    "tie_word_embeddings": true,
    "tokenizer_class": null,
    "top_k": 50,
    "top_p": 1.0,
    "torch_dtype": null,
    "torchscript": false,
    "transformers_version": "4.31.0.dev0",
    "typical_p": 1.0,
    "use_bfloat16": false
  }
}

[INFO|modeling_utils.py:2601] 2023-05-08 01:07:21,293 >> loading weights file /work/models/taiyi-clip-roberta/pytorch_model.bin
[INFO|configuration_utils.py:710] 2023-05-08 01:07:23,280 >> loading configuration file /work/models/Taiyi-CLIP-Roberta-102M-Chinese/config.json
[INFO|configuration_utils.py:768] 2023-05-08 01:07:23,284 >> Model config BertConfig {
  "_name_or_path": "hfl/chinese-roberta-wwm-ext",
  "add_cross_attention": true,
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "directionality": "bidi",
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17",
    "18": "LABEL_18",
    "19": "LABEL_19",
    "20": "LABEL_20",
    "21": "LABEL_21",
    "22": "LABEL_22",
    "23": "LABEL_23",
    "24": "LABEL_24",
    "25": "LABEL_25",
    "26": "LABEL_26",
    "27": "LABEL_27",
    "28": "LABEL_28",
    "29": "LABEL_29",
    "30": "LABEL_30",
    "31": "LABEL_31",
    "32": "LABEL_32",
    "33": "LABEL_33",
    "34": "LABEL_34",
    "35": "LABEL_35",
    "36": "LABEL_36",
    "37": "LABEL_37",
    "38": "LABEL_38",
    "39": "LABEL_39",
    "40": "LABEL_40",
    "41": "LABEL_41",
    "42": "LABEL_42",
    "43": "LABEL_43",
    "44": "LABEL_44",
    "45": "LABEL_45",
    "46": "LABEL_46",
    "47": "LABEL_47",
    "48": "LABEL_48",
    "49": "LABEL_49",
    "50": "LABEL_50",
    "51": "LABEL_51",
    "52": "LABEL_52",
    "53": "LABEL_53",
    "54": "LABEL_54",
    "55": "LABEL_55",
    "56": "LABEL_56",
    "57": "LABEL_57",
    "58": "LABEL_58",
    "59": "LABEL_59",
    "60": "LABEL_60",
    "61": "LABEL_61",
    "62": "LABEL_62",
    "63": "LABEL_63",
    "64": "LABEL_64",
    "65": "LABEL_65",
    "66": "LABEL_66",
    "67": "LABEL_67",
    "68": "LABEL_68",
    "69": "LABEL_69",
    "70": "LABEL_70",
    "71": "LABEL_71",
    "72": "LABEL_72",
    "73": "LABEL_73",
    "74": "LABEL_74",
    "75": "LABEL_75",
    "76": "LABEL_76",
    "77": "LABEL_77",
    "78": "LABEL_78",
    "79": "LABEL_79",
    "80": "LABEL_80",
    "81": "LABEL_81",
    "82": "LABEL_82",
    "83": "LABEL_83",
    "84": "LABEL_84",
    "85": "LABEL_85",
    "86": "LABEL_86",
    "87": "LABEL_87",
    "88": "LABEL_88",
    "89": "LABEL_89",
    "90": "LABEL_90",
    "91": "LABEL_91",
    "92": "LABEL_92",
    "93": "LABEL_93",
    "94": "LABEL_94",
    "95": "LABEL_95",
    "96": "LABEL_96",
    "97": "LABEL_97",
    "98": "LABEL_98",
    "99": "LABEL_99",
    "100": "LABEL_100",
    "101": "LABEL_101",
    "102": "LABEL_102",
    "103": "LABEL_103",
    "104": "LABEL_104",
    "105": "LABEL_105",
    "106": "LABEL_106",
    "107": "LABEL_107",
    "108": "LABEL_108",
    "109": "LABEL_109",
    "110": "LABEL_110",
    "111": "LABEL_111",
    "112": "LABEL_112",
    "113": "LABEL_113",
    "114": "LABEL_114",
    "115": "LABEL_115",
    "116": "LABEL_116",
    "117": "LABEL_117",
    "118": "LABEL_118",
    "119": "LABEL_119",
    "120": "LABEL_120",
    "121": "LABEL_121",
    "122": "LABEL_122",
    "123": "LABEL_123",
    "124": "LABEL_124",
    "125": "LABEL_125",
    "126": "LABEL_126",
    "127": "LABEL_127",
    "128": "LABEL_128",
    "129": "LABEL_129",
    "130": "LABEL_130",
    "131": "LABEL_131",
    "132": "LABEL_132",
    "133": "LABEL_133",
    "134": "LABEL_134",
    "135": "LABEL_135",
    "136": "LABEL_136",
    "137": "LABEL_137",
    "138": "LABEL_138",
    "139": "LABEL_139",
    "140": "LABEL_140",
    "141": "LABEL_141",
    "142": "LABEL_142",
    "143": "LABEL_143",
    "144": "LABEL_144",
    "145": "LABEL_145",
    "146": "LABEL_146",
    "147": "LABEL_147",
    "148": "LABEL_148",
    "149": "LABEL_149",
    "150": "LABEL_150",
    "151": "LABEL_151",
    "152": "LABEL_152",
    "153": "LABEL_153",
    "154": "LABEL_154",
    "155": "LABEL_155",
    "156": "LABEL_156",
    "157": "LABEL_157",
    "158": "LABEL_158",
    "159": "LABEL_159",
    "160": "LABEL_160",
    "161": "LABEL_161",
    "162": "LABEL_162",
    "163": "LABEL_163",
    "164": "LABEL_164",
    "165": "LABEL_165",
    "166": "LABEL_166",
    "167": "LABEL_167",
    "168": "LABEL_168",
    "169": "LABEL_169",
    "170": "LABEL_170",
    "171": "LABEL_171",
    "172": "LABEL_172",
    "173": "LABEL_173",
    "174": "LABEL_174",
    "175": "LABEL_175",
    "176": "LABEL_176",
    "177": "LABEL_177",
    "178": "LABEL_178",
    "179": "LABEL_179",
    "180": "LABEL_180",
    "181": "LABEL_181",
    "182": "LABEL_182",
    "183": "LABEL_183",
    "184": "LABEL_184",
    "185": "LABEL_185",
    "186": "LABEL_186",
    "187": "LABEL_187",
    "188": "LABEL_188",
    "189": "LABEL_189",
    "190": "LABEL_190",
    "191": "LABEL_191",
    "192": "LABEL_192",
    "193": "LABEL_193",
    "194": "LABEL_194",
    "195": "LABEL_195",
    "196": "LABEL_196",
    "197": "LABEL_197",
    "198": "LABEL_198",
    "199": "LABEL_199",
    "200": "LABEL_200",
    "201": "LABEL_201",
    "202": "LABEL_202",
    "203": "LABEL_203",
    "204": "LABEL_204",
    "205": "LABEL_205",
    "206": "LABEL_206",
    "207": "LABEL_207",
    "208": "LABEL_208",
    "209": "LABEL_209",
    "210": "LABEL_210",
    "211": "LABEL_211",
    "212": "LABEL_212",
    "213": "LABEL_213",
    "214": "LABEL_214",
    "215": "LABEL_215",
    "216": "LABEL_216",
    "217": "LABEL_217",
    "218": "LABEL_218",
    "219": "LABEL_219",
    "220": "LABEL_220",
    "221": "LABEL_221",
    "222": "LABEL_222",
    "223": "LABEL_223",
    "224": "LABEL_224",
    "225": "LABEL_225",
    "226": "LABEL_226",
    "227": "LABEL_227",
    "228": "LABEL_228",
    "229": "LABEL_229",
    "230": "LABEL_230",
    "231": "LABEL_231",
    "232": "LABEL_232",
    "233": "LABEL_233",
    "234": "LABEL_234",
    "235": "LABEL_235",
    "236": "LABEL_236",
    "237": "LABEL_237",
    "238": "LABEL_238",
    "239": "LABEL_239",
    "240": "LABEL_240",
    "241": "LABEL_241",
    "242": "LABEL_242",
    "243": "LABEL_243",
    "244": "LABEL_244",
    "245": "LABEL_245",
    "246": "LABEL_246",
    "247": "LABEL_247",
    "248": "LABEL_248",
    "249": "LABEL_249",
    "250": "LABEL_250",
    "251": "LABEL_251",
    "252": "LABEL_252",
    "253": "LABEL_253",
    "254": "LABEL_254",
    "255": "LABEL_255",
    "256": "LABEL_256",
    "257": "LABEL_257",
    "258": "LABEL_258",
    "259": "LABEL_259",
    "260": "LABEL_260",
    "261": "LABEL_261",
    "262": "LABEL_262",
    "263": "LABEL_263",
    "264": "LABEL_264",
    "265": "LABEL_265",
    "266": "LABEL_266",
    "267": "LABEL_267",
    "268": "LABEL_268",
    "269": "LABEL_269",
    "270": "LABEL_270",
    "271": "LABEL_271",
    "272": "LABEL_272",
    "273": "LABEL_273",
    "274": "LABEL_274",
    "275": "LABEL_275",
    "276": "LABEL_276",
    "277": "LABEL_277",
    "278": "LABEL_278",
    "279": "LABEL_279",
    "280": "LABEL_280",
    "281": "LABEL_281",
    "282": "LABEL_282",
    "283": "LABEL_283",
    "284": "LABEL_284",
    "285": "LABEL_285",
    "286": "LABEL_286",
    "287": "LABEL_287",
    "288": "LABEL_288",
    "289": "LABEL_289",
    "290": "LABEL_290",
    "291": "LABEL_291",
    "292": "LABEL_292",
    "293": "LABEL_293",
    "294": "LABEL_294",
    "295": "LABEL_295",
    "296": "LABEL_296",
    "297": "LABEL_297",
    "298": "LABEL_298",
    "299": "LABEL_299",
    "300": "LABEL_300",
    "301": "LABEL_301",
    "302": "LABEL_302",
    "303": "LABEL_303",
    "304": "LABEL_304",
    "305": "LABEL_305",
    "306": "LABEL_306",
    "307": "LABEL_307",
    "308": "LABEL_308",
    "309": "LABEL_309",
    "310": "LABEL_310",
    "311": "LABEL_311",
    "312": "LABEL_312",
    "313": "LABEL_313",
    "314": "LABEL_314",
    "315": "LABEL_315",
    "316": "LABEL_316",
    "317": "LABEL_317",
    "318": "LABEL_318",
    "319": "LABEL_319",
    "320": "LABEL_320",
    "321": "LABEL_321",
    "322": "LABEL_322",
    "323": "LABEL_323",
    "324": "LABEL_324",
    "325": "LABEL_325",
    "326": "LABEL_326",
    "327": "LABEL_327",
    "328": "LABEL_328",
    "329": "LABEL_329",
    "330": "LABEL_330",
    "331": "LABEL_331",
    "332": "LABEL_332",
    "333": "LABEL_333",
    "334": "LABEL_334",
    "335": "LABEL_335",
    "336": "LABEL_336",
    "337": "LABEL_337",
    "338": "LABEL_338",
    "339": "LABEL_339",
    "340": "LABEL_340",
    "341": "LABEL_341",
    "342": "LABEL_342",
    "343": "LABEL_343",
    "344": "LABEL_344",
    "345": "LABEL_345",
    "346": "LABEL_346",
    "347": "LABEL_347",
    "348": "LABEL_348",
    "349": "LABEL_349",
    "350": "LABEL_350",
    "351": "LABEL_351",
    "352": "LABEL_352",
    "353": "LABEL_353",
    "354": "LABEL_354",
    "355": "LABEL_355",
    "356": "LABEL_356",
    "357": "LABEL_357",
    "358": "LABEL_358",
    "359": "LABEL_359",
    "360": "LABEL_360",
    "361": "LABEL_361",
    "362": "LABEL_362",
    "363": "LABEL_363",
    "364": "LABEL_364",
    "365": "LABEL_365",
    "366": "LABEL_366",
    "367": "LABEL_367",
    "368": "LABEL_368",
    "369": "LABEL_369",
    "370": "LABEL_370",
    "371": "LABEL_371",
    "372": "LABEL_372",
    "373": "LABEL_373",
    "374": "LABEL_374",
    "375": "LABEL_375",
    "376": "LABEL_376",
    "377": "LABEL_377",
    "378": "LABEL_378",
    "379": "LABEL_379",
    "380": "LABEL_380",
    "381": "LABEL_381",
    "382": "LABEL_382",
    "383": "LABEL_383",
    "384": "LABEL_384",
    "385": "LABEL_385",
    "386": "LABEL_386",
    "387": "LABEL_387",
    "388": "LABEL_388",
    "389": "LABEL_389",
    "390": "LABEL_390",
    "391": "LABEL_391",
    "392": "LABEL_392",
    "393": "LABEL_393",
    "394": "LABEL_394",
    "395": "LABEL_395",
    "396": "LABEL_396",
    "397": "LABEL_397",
    "398": "LABEL_398",
    "399": "LABEL_399",
    "400": "LABEL_400",
    "401": "LABEL_401",
    "402": "LABEL_402",
    "403": "LABEL_403",
    "404": "LABEL_404",
    "405": "LABEL_405",
    "406": "LABEL_406",
    "407": "LABEL_407",
    "408": "LABEL_408",
    "409": "LABEL_409",
    "410": "LABEL_410",
    "411": "LABEL_411",
    "412": "LABEL_412",
    "413": "LABEL_413",
    "414": "LABEL_414",
    "415": "LABEL_415",
    "416": "LABEL_416",
    "417": "LABEL_417",
    "418": "LABEL_418",
    "419": "LABEL_419",
    "420": "LABEL_420",
    "421": "LABEL_421",
    "422": "LABEL_422",
    "423": "LABEL_423",
    "424": "LABEL_424",
    "425": "LABEL_425",
    "426": "LABEL_426",
    "427": "LABEL_427",
    "428": "LABEL_428",
    "429": "LABEL_429",
    "430": "LABEL_430",
    "431": "LABEL_431",
    "432": "LABEL_432",
    "433": "LABEL_433",
    "434": "LABEL_434",
    "435": "LABEL_435",
    "436": "LABEL_436",
    "437": "LABEL_437",
    "438": "LABEL_438",
    "439": "LABEL_439",
    "440": "LABEL_440",
    "441": "LABEL_441",
    "442": "LABEL_442",
    "443": "LABEL_443",
    "444": "LABEL_444",
    "445": "LABEL_445",
    "446": "LABEL_446",
    "447": "LABEL_447",
    "448": "LABEL_448",
    "449": "LABEL_449",
    "450": "LABEL_450",
    "451": "LABEL_451",
    "452": "LABEL_452",
    "453": "LABEL_453",
    "454": "LABEL_454",
    "455": "LABEL_455",
    "456": "LABEL_456",
    "457": "LABEL_457",
    "458": "LABEL_458",
    "459": "LABEL_459",
    "460": "LABEL_460",
    "461": "LABEL_461",
    "462": "LABEL_462",
    "463": "LABEL_463",
    "464": "LABEL_464",
    "465": "LABEL_465",
    "466": "LABEL_466",
    "467": "LABEL_467",
    "468": "LABEL_468",
    "469": "LABEL_469",
    "470": "LABEL_470",
    "471": "LABEL_471",
    "472": "LABEL_472",
    "473": "LABEL_473",
    "474": "LABEL_474",
    "475": "LABEL_475",
    "476": "LABEL_476",
    "477": "LABEL_477",
    "478": "LABEL_478",
    "479": "LABEL_479",
    "480": "LABEL_480",
    "481": "LABEL_481",
    "482": "LABEL_482",
    "483": "LABEL_483",
    "484": "LABEL_484",
    "485": "LABEL_485",
    "486": "LABEL_486",
    "487": "LABEL_487",
    "488": "LABEL_488",
    "489": "LABEL_489",
    "490": "LABEL_490",
    "491": "LABEL_491",
    "492": "LABEL_492",
    "493": "LABEL_493",
    "494": "LABEL_494",
    "495": "LABEL_495",
    "496": "LABEL_496",
    "497": "LABEL_497",
    "498": "LABEL_498",
    "499": "LABEL_499",
    "500": "LABEL_500",
    "501": "LABEL_501",
    "502": "LABEL_502",
    "503": "LABEL_503",
    "504": "LABEL_504",
    "505": "LABEL_505",
    "506": "LABEL_506",
    "507": "LABEL_507",
    "508": "LABEL_508",
    "509": "LABEL_509",
    "510": "LABEL_510",
    "511": "LABEL_511"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_100": 100,
    "LABEL_101": 101,
    "LABEL_102": 102,
    "LABEL_103": 103,
    "LABEL_104": 104,
    "LABEL_105": 105,
    "LABEL_106": 106,
    "LABEL_107": 107,
    "LABEL_108": 108,
    "LABEL_109": 109,
    "LABEL_11": 11,
    "LABEL_110": 110,
    "LABEL_111": 111,
    "LABEL_112": 112,
    "LABEL_113": 113,
    "LABEL_114": 114,
    "LABEL_115": 115,
    "LABEL_116": 116,
    "LABEL_117": 117,
    "LABEL_118": 118,
    "LABEL_119": 119,
    "LABEL_12": 12,
    "LABEL_120": 120,
    "LABEL_121": 121,
    "LABEL_122": 122,
    "LABEL_123": 123,
    "LABEL_124": 124,
    "LABEL_125": 125,
    "LABEL_126": 126,
    "LABEL_127": 127,
    "LABEL_128": 128,
    "LABEL_129": 129,
    "LABEL_13": 13,
    "LABEL_130": 130,
    "LABEL_131": 131,
    "LABEL_132": 132,
    "LABEL_133": 133,
    "LABEL_134": 134,
    "LABEL_135": 135,
    "LABEL_136": 136,
    "LABEL_137": 137,
    "LABEL_138": 138,
    "LABEL_139": 139,
    "LABEL_14": 14,
    "LABEL_140": 140,
    "LABEL_141": 141,
    "LABEL_142": 142,
    "LABEL_143": 143,
    "LABEL_144": 144,
    "LABEL_145": 145,
    "LABEL_146": 146,
    "LABEL_147": 147,
    "LABEL_148": 148,
    "LABEL_149": 149,
    "LABEL_15": 15,
    "LABEL_150": 150,
    "LABEL_151": 151,
    "LABEL_152": 152,
    "LABEL_153": 153,
    "LABEL_154": 154,
    "LABEL_155": 155,
    "LABEL_156": 156,
    "LABEL_157": 157,
    "LABEL_158": 158,
    "LABEL_159": 159,
    "LABEL_16": 16,
    "LABEL_160": 160,
    "LABEL_161": 161,
    "LABEL_162": 162,
    "LABEL_163": 163,
    "LABEL_164": 164,
    "LABEL_165": 165,
    "LABEL_166": 166,
    "LABEL_167": 167,
    "LABEL_168": 168,
    "LABEL_169": 169,
    "LABEL_17": 17,
    "LABEL_170": 170,
    "LABEL_171": 171,
    "LABEL_172": 172,
    "LABEL_173": 173,
    "LABEL_174": 174,
    "LABEL_175": 175,
    "LABEL_176": 176,
    "LABEL_177": 177,
    "LABEL_178": 178,
    "LABEL_179": 179,
    "LABEL_18": 18,
    "LABEL_180": 180,
    "LABEL_181": 181,
    "LABEL_182": 182,
    "LABEL_183": 183,
    "LABEL_184": 184,
    "LABEL_185": 185,
    "LABEL_186": 186,
    "LABEL_187": 187,
    "LABEL_188": 188,
    "LABEL_189": 189,
    "LABEL_19": 19,
    "LABEL_190": 190,
    "LABEL_191": 191,
    "LABEL_192": 192,
    "LABEL_193": 193,
    "LABEL_194": 194,
    "LABEL_195": 195,
    "LABEL_196": 196,
    "LABEL_197": 197,
    "LABEL_198": 198,
    "LABEL_199": 199,
    "LABEL_2": 2,
    "LABEL_20": 20,
    "LABEL_200": 200,
    "LABEL_201": 201,
    "LABEL_202": 202,
    "LABEL_203": 203,
    "LABEL_204": 204,
    "LABEL_205": 205,
    "LABEL_206": 206,
    "LABEL_207": 207,
    "LABEL_208": 208,
    "LABEL_209": 209,
    "LABEL_21": 21,
    "LABEL_210": 210,
    "LABEL_211": 211,
    "LABEL_212": 212,
    "LABEL_213": 213,
    "LABEL_214": 214,
    "LABEL_215": 215,
    "LABEL_216": 216,
    "LABEL_217": 217,
    "LABEL_218": 218,
    "LABEL_219": 219,
    "LABEL_22": 22,
    "LABEL_220": 220,
    "LABEL_221": 221,
    "LABEL_222": 222,
    "LABEL_223": 223,
    "LABEL_224": 224,
    "LABEL_225": 225,
    "LABEL_226": 226,
    "LABEL_227": 227,
    "LABEL_228": 228,
    "LABEL_229": 229,
    "LABEL_23": 23,
    "LABEL_230": 230,
    "LABEL_231": 231,
    "LABEL_232": 232,
    "LABEL_233": 233,
    "LABEL_234": 234,
    "LABEL_235": 235,
    "LABEL_236": 236,
    "LABEL_237": 237,
    "LABEL_238": 238,
    "LABEL_239": 239,
    "LABEL_24": 24,
    "LABEL_240": 240,
    "LABEL_241": 241,
    "LABEL_242": 242,
    "LABEL_243": 243,
    "LABEL_244": 244,
    "LABEL_245": 245,
    "LABEL_246": 246,
    "LABEL_247": 247,
    "LABEL_248": 248,
    "LABEL_249": 249,
    "LABEL_25": 25,
    "LABEL_250": 250,
    "LABEL_251": 251,
    "LABEL_252": 252,
    "LABEL_253": 253,
    "LABEL_254": 254,
    "LABEL_255": 255,
    "LABEL_256": 256,
    "LABEL_257": 257,
    "LABEL_258": 258,
    "LABEL_259": 259,
    "LABEL_26": 26,
    "LABEL_260": 260,
    "LABEL_261": 261,
    "LABEL_262": 262,
    "LABEL_263": 263,
    "LABEL_264": 264,
    "LABEL_265": 265,
    "LABEL_266": 266,
    "LABEL_267": 267,
    "LABEL_268": 268,
    "LABEL_269": 269,
    "LABEL_27": 27,
    "LABEL_270": 270,
    "LABEL_271": 271,
    "LABEL_272": 272,
    "LABEL_273": 273,
    "LABEL_274": 274,
    "LABEL_275": 275,
    "LABEL_276": 276,
    "LABEL_277": 277,
    "LABEL_278": 278,
    "LABEL_279": 279,
    "LABEL_28": 28,
    "LABEL_280": 280,
    "LABEL_281": 281,
    "LABEL_282": 282,
    "LABEL_283": 283,
    "LABEL_284": 284,
    "LABEL_285": 285,
    "LABEL_286": 286,
    "LABEL_287": 287,
    "LABEL_288": 288,
    "LABEL_289": 289,
    "LABEL_29": 29,
    "LABEL_290": 290,
    "LABEL_291": 291,
    "LABEL_292": 292,
    "LABEL_293": 293,
    "LABEL_294": 294,
    "LABEL_295": 295,
    "LABEL_296": 296,
    "LABEL_297": 297,
    "LABEL_298": 298,
    "LABEL_299": 299,
    "LABEL_3": 3,
    "LABEL_30": 30,
    "LABEL_300": 300,
    "LABEL_301": 301,
    "LABEL_302": 302,
    "LABEL_303": 303,
    "LABEL_304": 304,
    "LABEL_305": 305,
    "LABEL_306": 306,
    "LABEL_307": 307,
    "LABEL_308": 308,
    "LABEL_309": 309,
    "LABEL_31": 31,
    "LABEL_310": 310,
    "LABEL_311": 311,
    "LABEL_312": 312,
    "LABEL_313": 313,
    "LABEL_314": 314,
    "LABEL_315": 315,
    "LABEL_316": 316,
    "LABEL_317": 317,
    "LABEL_318": 318,
    "LABEL_319": 319,
    "LABEL_32": 32,
    "LABEL_320": 320,
    "LABEL_321": 321,
    "LABEL_322": 322,
    "LABEL_323": 323,
    "LABEL_324": 324,
    "LABEL_325": 325,
    "LABEL_326": 326,
    "LABEL_327": 327,
    "LABEL_328": 328,
    "LABEL_329": 329,
    "LABEL_33": 33,
    "LABEL_330": 330,
    "LABEL_331": 331,
    "LABEL_332": 332,
    "LABEL_333": 333,
    "LABEL_334": 334,
    "LABEL_335": 335,
    "LABEL_336": 336,
    "LABEL_337": 337,
    "LABEL_338": 338,
    "LABEL_339": 339,
    "LABEL_34": 34,
    "LABEL_340": 340,
    "LABEL_341": 341,
    "LABEL_342": 342,
    "LABEL_343": 343,
    "LABEL_344": 344,
    "LABEL_345": 345,
    "LABEL_346": 346,
    "LABEL_347": 347,
    "LABEL_348": 348,
    "LABEL_349": 349,
    "LABEL_35": 35,
    "LABEL_350": 350,
    "LABEL_351": 351,
    "LABEL_352": 352,
    "LABEL_353": 353,
    "LABEL_354": 354,
    "LABEL_355": 355,
    "LABEL_356": 356,
    "LABEL_357": 357,
    "LABEL_358": 358,
    "LABEL_359": 359,
    "LABEL_36": 36,
    "LABEL_360": 360,
    "LABEL_361": 361,
    "LABEL_362": 362,
    "LABEL_363": 363,
    "LABEL_364": 364,
    "LABEL_365": 365,
    "LABEL_366": 366,
    "LABEL_367": 367,
    "LABEL_368": 368,
    "LABEL_369": 369,
    "LABEL_37": 37,
    "LABEL_370": 370,
    "LABEL_371": 371,
    "LABEL_372": 372,
    "LABEL_373": 373,
    "LABEL_374": 374,
    "LABEL_375": 375,
    "LABEL_376": 376,
    "LABEL_377": 377,
    "LABEL_378": 378,
    "LABEL_379": 379,
    "LABEL_38": 38,
    "LABEL_380": 380,
    "LABEL_381": 381,
    "LABEL_382": 382,
    "LABEL_383": 383,
    "LABEL_384": 384,
    "LABEL_385": 385,
    "LABEL_386": 386,
    "LABEL_387": 387,
    "LABEL_388": 388,
    "LABEL_389": 389,
    "LABEL_39": 39,
    "LABEL_390": 390,
    "LABEL_391": 391,
    "LABEL_392": 392,
    "LABEL_393": 393,
    "LABEL_394": 394,
    "LABEL_395": 395,
    "LABEL_396": 396,
    "LABEL_397": 397,
    "LABEL_398": 398,
    "LABEL_399": 399,
    "LABEL_4": 4,
    "LABEL_40": 40,
    "LABEL_400": 400,
    "LABEL_401": 401,
    "LABEL_402": 402,
    "LABEL_403": 403,
    "LABEL_404": 404,
    "LABEL_405": 405,
    "LABEL_406": 406,
    "LABEL_407": 407,
    "LABEL_408": 408,
    "LABEL_409": 409,
    "LABEL_41": 41,
    "LABEL_410": 410,
    "LABEL_411": 411,
    "LABEL_412": 412,
    "LABEL_413": 413,
    "LABEL_414": 414,
    "LABEL_415": 415,
    "LABEL_416": 416,
    "LABEL_417": 417,
    "LABEL_418": 418,
    "LABEL_419": 419,
    "LABEL_42": 42,
    "LABEL_420": 420,
    "LABEL_421": 421,
    "LABEL_422": 422,
    "LABEL_423": 423,
    "LABEL_424": 424,
    "LABEL_425": 425,
    "LABEL_426": 426,
    "LABEL_427": 427,
    "LABEL_428": 428,
    "LABEL_429": 429,
    "LABEL_43": 43,
    "LABEL_430": 430,
    "LABEL_431": 431,
    "LABEL_432": 432,
    "LABEL_433": 433,
    "LABEL_434": 434,
    "LABEL_435": 435,
    "LABEL_436": 436,
    "LABEL_437": 437,
    "LABEL_438": 438,
    "LABEL_439": 439,
    "LABEL_44": 44,
    "LABEL_440": 440,
    "LABEL_441": 441,
    "LABEL_442": 442,
    "LABEL_443": 443,
    "LABEL_444": 444,
    "LABEL_445": 445,
    "LABEL_446": 446,
    "LABEL_447": 447,
    "LABEL_448": 448,
    "LABEL_449": 449,
    "LABEL_45": 45,
    "LABEL_450": 450,
    "LABEL_451": 451,
    "LABEL_452": 452,
    "LABEL_453": 453,
    "LABEL_454": 454,
    "LABEL_455": 455,
    "LABEL_456": 456,
    "LABEL_457": 457,
    "LABEL_458": 458,
    "LABEL_459": 459,
    "LABEL_46": 46,
    "LABEL_460": 460,
    "LABEL_461": 461,
    "LABEL_462": 462,
    "LABEL_463": 463,
    "LABEL_464": 464,
    "LABEL_465": 465,
    "LABEL_466": 466,
    "LABEL_467": 467,
    "LABEL_468": 468,
    "LABEL_469": 469,
    "LABEL_47": 47,
    "LABEL_470": 470,
    "LABEL_471": 471,
    "LABEL_472": 472,
    "LABEL_473": 473,
    "LABEL_474": 474,
    "LABEL_475": 475,
    "LABEL_476": 476,
    "LABEL_477": 477,
    "LABEL_478": 478,
    "LABEL_479": 479,
    "LABEL_48": 48,
    "LABEL_480": 480,
    "LABEL_481": 481,
    "LABEL_482": 482,
    "LABEL_483": 483,
    "LABEL_484": 484,
    "LABEL_485": 485,
    "LABEL_486": 486,
    "LABEL_487": 487,
    "LABEL_488": 488,
    "LABEL_489": 489,
    "LABEL_49": 49,
    "LABEL_490": 490,
    "LABEL_491": 491,
    "LABEL_492": 492,
    "LABEL_493": 493,
    "LABEL_494": 494,
    "LABEL_495": 495,
    "LABEL_496": 496,
    "LABEL_497": 497,
    "LABEL_498": 498,
    "LABEL_499": 499,
    "LABEL_5": 5,
    "LABEL_50": 50,
    "LABEL_500": 500,
    "LABEL_501": 501,
    "LABEL_502": 502,
    "LABEL_503": 503,
    "LABEL_504": 504,
    "LABEL_505": 505,
    "LABEL_506": 506,
    "LABEL_507": 507,
    "LABEL_508": 508,
    "LABEL_509": 509,
    "LABEL_51": 51,
    "LABEL_510": 510,
    "LABEL_511": 511,
    "LABEL_52": 52,
    "LABEL_53": 53,
    "LABEL_54": 54,
    "LABEL_55": 55,
    "LABEL_56": 56,
    "LABEL_57": 57,
    "LABEL_58": 58,
    "LABEL_59": 59,
    "LABEL_6": 6,
    "LABEL_60": 60,
    "LABEL_61": 61,
    "LABEL_62": 62,
    "LABEL_63": 63,
    "LABEL_64": 64,
    "LABEL_65": 65,
    "LABEL_66": 66,
    "LABEL_67": 67,
    "LABEL_68": 68,
    "LABEL_69": 69,
    "LABEL_7": 7,
    "LABEL_70": 70,
    "LABEL_71": 71,
    "LABEL_72": 72,
    "LABEL_73": 73,
    "LABEL_74": 74,
    "LABEL_75": 75,
    "LABEL_76": 76,
    "LABEL_77": 77,
    "LABEL_78": 78,
    "LABEL_79": 79,
    "LABEL_8": 8,
    "LABEL_80": 80,
    "LABEL_81": 81,
    "LABEL_82": 82,
    "LABEL_83": 83,
    "LABEL_84": 84,
    "LABEL_85": 85,
    "LABEL_86": 86,
    "LABEL_87": 87,
    "LABEL_88": 88,
    "LABEL_89": 89,
    "LABEL_9": 9,
    "LABEL_90": 90,
    "LABEL_91": 91,
    "LABEL_92": 92,
    "LABEL_93": 93,
    "LABEL_94": 94,
    "LABEL_95": 95,
    "LABEL_96": 96,
    "LABEL_97": 97,
    "LABEL_98": 98,
    "LABEL_99": 99
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "position_embedding_type": "absolute",
  "torch_dtype": "float32",
  "transformers_version": "4.31.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 21128
}

[INFO|modeling_utils.py:2601] 2023-05-08 01:07:23,285 >> loading weights file /work/models/Taiyi-CLIP-Roberta-102M-Chinese/pytorch_model.bin
[INFO|configuration_utils.py:599] 2023-05-08 01:07:26,192 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "pad_token_id": 0,
  "transformers_version": "4.31.0.dev0"
}

[INFO|modeling_utils.py:3317] 2023-05-08 01:07:30,268 >> Some weights of the model checkpoint at /work/models/Taiyi-CLIP-Roberta-102M-Chinese were not used when initializing BertLMHeadModel: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']
- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3329] 2023-05-08 01:07:30,269 >> Some weights of BertLMHeadModel were not initialized from the model checkpoint at /work/models/Taiyi-CLIP-Roberta-102M-Chinese and are newly initialized: ['bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'cls.predictions.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:2950] 2023-05-08 01:07:30,280 >> Generation config file not found, using a generation config created from the model config.
[INFO|modeling_utils.py:3317] 2023-05-08 01:07:31,664 >> Some weights of the model checkpoint at /work/models/taiyi-clip-roberta were not used when initializing CLIPForVQA: ['vision_model.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.vision_model.pre_layrnorm.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.vision_model.post_layernorm.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.vision_model.embeddings.class_embedding', 'vision_model.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.vision_model.pre_layrnorm.bias', 'vision_model.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.vision_model.post_layernorm.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.vision_model.embeddings.position_embedding.weight', 'vision_model.vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.vision_model.embeddings.patch_embedding.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.q_proj.bias']
- This IS expected if you are initializing CLIPForVQA from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CLIPForVQA from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3329] 2023-05-08 01:07:31,665 >> Some weights of CLIPForVQA were not initialized from the model checkpoint at /work/models/taiyi-clip-roberta and are newly initialized: ['text_decoder.bert.encoder.layer.10.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.1.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.6.output.dense.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.attention.self.value.weight', 'text_decoder.bert.encoder.layer.10.attention.self.value.bias', 'text_decoder.bert.encoder.layer.2.attention.self.value.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.0.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.5.attention.self.key.weight', 'text_decoder.bert.encoder.layer.0.attention.self.query.bias', 'text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'text_decoder.bert.embeddings.LayerNorm.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.dense.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.0.attention.self.query.weight', 'text_decoder.bert.encoder.layer.3.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.attention.self.query.bias', 'text_decoder.bert.encoder.layer.5.output.LayerNorm.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.value.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'text_decoder.bert.encoder.layer.8.attention.self.value.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.value.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'text_decoder.bert.encoder.layer.3.output.dense.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'text_decoder.bert.encoder.layer.2.output.dense.weight', 'text_decoder.bert.encoder.layer.7.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.10.attention.self.query.weight', 'text_decoder.cls.predictions.bias', 'text_decoder.bert.encoder.layer.10.intermediate.dense.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'text_decoder.bert.encoder.layer.5.attention.self.value.weight', 'text_decoder.bert.encoder.layer.7.attention.self.key.bias', 'text_decoder.bert.encoder.layer.9.output.LayerNorm.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.key.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'text_decoder.bert.encoder.layer.5.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.9.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.attention.self.key.bias', 'text_decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.dense.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.1.attention.self.query.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.3.attention.self.key.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.dense.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.3.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.0.attention.self.key.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.dense.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.9.output.dense.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.5.attention.self.query.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'text_decoder.cls.predictions.decoder.weight', 'text_decoder.bert.encoder.layer.8.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.9.intermediate.dense.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'text_decoder.bert.encoder.layer.11.attention.self.value.bias', 'text_decoder.bert.encoder.layer.11.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.8.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.2.attention.self.query.weight', 'text_decoder.bert.encoder.layer.10.crossattention.self.key.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.6.crossattention.self.value.bias', 'image_input_projection.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'text_decoder.bert.encoder.layer.6.output.dense.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.9.attention.self.value.weight', 'vision_model.pre_layrnorm.weight', 'text_decoder.bert.encoder.layer.2.attention.self.key.bias', 'text_decoder.bert.encoder.layer.10.attention.self.key.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'text_decoder.bert.encoder.layer.4.intermediate.dense.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'text_decoder.bert.encoder.layer.4.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.10.output.LayerNorm.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.1.output.LayerNorm.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.6.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.10.attention.self.value.weight', 'text_decoder.bert.encoder.layer.11.attention.output.dense.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.6.attention.self.key.bias', 'text_decoder.cls.predictions.transform.dense.weight', 'text_decoder.bert.encoder.layer.8.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.5.attention.output.dense.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.key.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.8.crossattention.output.dense.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.attention.self.value.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.query.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.8.attention.self.query.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'text_decoder.bert.encoder.layer.7.output.dense.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'text_decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.10.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.intermediate.dense.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'text_decoder.bert.encoder.layer.6.attention.self.query.weight', 'text_decoder.bert.encoder.layer.6.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.11.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.query.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'text_decoder.bert.encoder.layer.4.attention.self.key.weight', 'text_decoder.bert.encoder.layer.4.output.dense.weight', 'text_decoder.bert.encoder.layer.9.attention.self.query.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.1.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.9.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.11.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.6.crossattention.output.dense.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'text_decoder.bert.encoder.layer.11.attention.self.query.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.1.output.LayerNorm.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'text_decoder.bert.embeddings.LayerNorm.bias', 'text_decoder.bert.encoder.layer.6.attention.self.value.weight', 'text_decoder.bert.encoder.layer.5.attention.output.dense.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.value.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.1.attention.self.value.bias', 'text_decoder.bert.encoder.layer.0.attention.self.value.bias', 'text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.9.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.5.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.8.output.dense.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.8.output.LayerNorm.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.7.crossattention.output.dense.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'text_decoder.bert.encoder.layer.2.attention.self.value.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.10.output.dense.bias', 'text_decoder.bert.encoder.layer.7.output.dense.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.key.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'text_decoder.bert.encoder.layer.7.attention.self.query.bias', 'text_decoder.bert.encoder.layer.10.output.LayerNorm.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'text_decoder.bert.encoder.layer.0.output.dense.bias', 'text_decoder.bert.encoder.layer.11.intermediate.dense.weight', 'text_decoder.cls.predictions.decoder.bias', 'text_decoder.bert.encoder.layer.9.intermediate.dense.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'text_decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.attention.output.dense.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.0.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.6.crossattention.output.dense.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.9.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.7.attention.self.value.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.0.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.attention.self.query.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.attention.self.key.bias', 'text_decoder.bert.encoder.layer.6.attention.self.query.bias', 'text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'text_decoder.bert.encoder.layer.0.attention.self.key.bias', 'text_decoder.bert.encoder.layer.10.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.9.attention.output.dense.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.1.output.dense.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'text_decoder.bert.encoder.layer.10.attention.output.dense.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.key.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.key.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.10.output.dense.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.3.intermediate.dense.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'text_decoder.bert.encoder.layer.8.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.7.crossattention.self.value.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'text_decoder.bert.encoder.layer.6.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.dense.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'text_decoder.bert.encoder.layer.9.attention.self.query.weight', 'text_decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.2.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.2.output.dense.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.4.attention.self.value.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.5.output.dense.weight', 'text_decoder.bert.encoder.layer.4.attention.self.query.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.0.attention.self.value.weight', 'text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.1.attention.self.value.weight', 'text_decoder.bert.encoder.layer.7.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.attention.self.value.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.dense.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'text_decoder.bert.encoder.layer.10.attention.self.key.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'text_decoder.bert.encoder.layer.7.attention.self.query.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'text_decoder.bert.encoder.layer.6.attention.self.key.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.7.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.output.dense.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.11.output.LayerNorm.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.attention.self.key.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.embeddings.patch_embedding.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.attention.self.query.weight', 'text_decoder.bert.encoder.layer.7.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.6.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.3.attention.self.key.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'text_decoder.bert.encoder.layer.8.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.1.attention.self.query.bias', 'text_decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'vision_model.pre_layrnorm.bias', 'text_decoder.bert.embeddings.word_embeddings.weight', 'text_decoder.cls.predictions.transform.dense.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'text_decoder.bert.encoder.layer.2.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.query.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.0.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.intermediate.dense.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.4.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.output.dense.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.query.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'text_decoder.cls.predictions.transform.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.10.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.11.output.dense.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.8.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.7.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.2.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.11.attention.self.key.bias', 'text_decoder.bert.encoder.layer.11.attention.self.value.weight', 'text_decoder.bert.encoder.layer.5.attention.self.query.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'text_decoder.bert.encoder.layer.7.crossattention.self.value.bias', 'vision_model.post_layernorm.bias', 'text_decoder.bert.encoder.layer.4.output.dense.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.value.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.3.attention.self.value.weight', 'text_decoder.cls.predictions.transform.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.key.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.7.attention.self.value.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'text_decoder.bert.encoder.layer.3.attention.self.query.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.0.crossattention.output.dense.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'text_decoder.bert.encoder.layer.3.output.dense.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.4.attention.self.query.bias', 'text_decoder.bert.encoder.layer.9.output.dense.bias', 'text_decoder.bert.encoder.layer.11.crossattention.self.key.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.3.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.1.output.dense.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.value.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.9.attention.output.dense.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.attention.self.key.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.7.attention.self.key.weight', 'text_decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'text_decoder.bert.encoder.layer.9.attention.self.key.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.10.attention.self.query.bias', 'text_decoder.bert.encoder.layer.1.attention.self.key.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'text_decoder.bert.encoder.layer.3.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'text_decoder.bert.encoder.layer.5.attention.self.value.bias', 'text_decoder.bert.encoder.layer.11.attention.self.key.weight', 'text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'text_decoder.bert.encoder.layer.8.crossattention.self.value.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.query.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.crossattention.output.dense.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.5.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.intermediate.dense.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'text_decoder.bert.encoder.layer.2.attention.self.key.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.8.attention.output.dense.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.9.attention.self.value.bias', 'text_decoder.bert.encoder.layer.3.attention.output.dense.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.11.crossattention.self.query.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'text_decoder.bert.encoder.layer.4.attention.self.key.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.key.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'text_decoder.bert.encoder.layer.11.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.6.attention.self.value.bias', 'text_decoder.bert.embeddings.position_embeddings.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.dense.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'text_decoder.bert.encoder.layer.8.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.5.output.dense.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'text_decoder.bert.encoder.layer.11.attention.self.query.bias', 'text_decoder.bert.encoder.layer.11.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.intermediate.dense.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'text_decoder.bert.encoder.layer.8.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.2.crossattention.self.query.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.attention.output.dense.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'text_decoder.bert.encoder.layer.7.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'text_decoder.bert.embeddings.token_type_embeddings.weight', 'text_decoder.bert.encoder.layer.4.output.LayerNorm.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'text_decoder.bert.encoder.layer.11.output.dense.bias', 'text_decoder.bert.encoder.layer.10.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.7.output.LayerNorm.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.6.intermediate.dense.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'text_decoder.bert.encoder.layer.10.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.6.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.key.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'text_decoder.bert.encoder.layer.2.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'text_decoder.bert.encoder.layer.0.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.9.attention.self.key.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.query.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Filter:   0%|          | 0/30903 [00:00<?, ? examples/s]Filter:   3%|▎         | 1000/30903 [00:00<00:14, 2126.68 examples/s]Filter:   6%|▋         | 2000/30903 [00:00<00:13, 2138.21 examples/s]Filter:  10%|▉         | 3000/30903 [00:01<00:12, 2252.97 examples/s]Filter:  13%|█▎        | 4000/30903 [00:01<00:11, 2321.65 examples/s]Filter:  16%|█▌        | 5000/30903 [00:02<00:11, 2302.17 examples/s]Filter:  19%|█▉        | 6000/30903 [00:02<00:10, 2394.80 examples/s]Filter:  23%|██▎       | 7000/30903 [00:02<00:09, 2573.06 examples/s]Filter:  26%|██▌       | 8000/30903 [00:03<00:08, 2566.03 examples/s]Filter:  29%|██▉       | 9000/30903 [00:03<00:08, 2586.09 examples/s]Filter:  32%|███▏      | 10000/30903 [00:04<00:08, 2515.56 examples/s]Filter:  36%|███▌      | 11000/30903 [00:04<00:08, 2444.14 examples/s]Filter:  39%|███▉      | 12000/30903 [00:04<00:07, 2464.90 examples/s]Filter:  42%|████▏     | 13000/30903 [00:05<00:07, 2401.29 examples/s]Filter:  45%|████▌     | 14000/30903 [00:05<00:07, 2370.50 examples/s]Filter:  49%|████▊     | 15000/30903 [00:06<00:06, 2351.95 examples/s]Filter:  52%|█████▏    | 16000/30903 [00:06<00:06, 2320.76 examples/s]Filter:  55%|█████▌    | 17000/30903 [00:07<00:05, 2361.13 examples/s]Filter:  58%|█████▊    | 18000/30903 [00:07<00:05, 2369.68 examples/s]Filter:  61%|██████▏   | 19000/30903 [00:07<00:05, 2346.29 examples/s]Filter:  65%|██████▍   | 20000/30903 [00:08<00:04, 2342.53 examples/s]Filter:  68%|██████▊   | 21000/30903 [00:08<00:04, 2348.92 examples/s]Filter:  71%|███████   | 22000/30903 [00:09<00:03, 2418.23 examples/s]Filter:  74%|███████▍  | 23000/30903 [00:09<00:03, 2391.22 examples/s]Filter:  78%|███████▊  | 24000/30903 [00:10<00:02, 2383.38 examples/s]Filter:  81%|████████  | 25000/30903 [00:10<00:02, 2355.86 examples/s]Filter:  84%|████████▍ | 26000/30903 [00:10<00:02, 2334.74 examples/s]Filter:  87%|████████▋ | 27000/30903 [00:11<00:01, 2291.17 examples/s]Filter:  91%|█████████ | 28000/30903 [00:11<00:01, 2340.56 examples/s]Filter:  94%|█████████▍| 29000/30903 [00:12<00:00, 2375.85 examples/s]Filter:  97%|█████████▋| 30000/30903 [00:12<00:00, 2368.78 examples/s]Filter: 100%|██████████| 30903/30903 [00:13<00:00, 2336.31 examples/s]                                                                      Running tokenizer on train dataset:   0%|          | 0/30903 [00:00<?, ? examples/s]Running tokenizer on train dataset:   3%|▎         | 1000/30903 [00:00<00:03, 7919.70 examples/s]Running tokenizer on train dataset:   6%|▋         | 2000/30903 [00:00<00:03, 8734.15 examples/s]Running tokenizer on train dataset:  13%|█▎        | 4000/30903 [00:00<00:02, 9639.98 examples/s]Running tokenizer on train dataset:  19%|█▉        | 6000/30903 [00:00<00:02, 10158.64 examples/s]Running tokenizer on train dataset:  23%|██▎       | 7000/30903 [00:00<00:03, 7560.61 examples/s] Running tokenizer on train dataset:  29%|██▉       | 9000/30903 [00:01<00:02, 8656.82 examples/s]Running tokenizer on train dataset:  36%|███▌      | 11000/30903 [00:01<00:02, 9269.84 examples/s]Running tokenizer on train dataset:  42%|████▏     | 13000/30903 [00:01<00:02, 8188.09 examples/s]Running tokenizer on train dataset:  49%|████▊     | 15000/30903 [00:01<00:01, 9113.23 examples/s]Running tokenizer on train dataset:  55%|█████▌    | 17000/30903 [00:01<00:01, 9916.31 examples/s]Running tokenizer on train dataset:  61%|██████▏   | 19000/30903 [00:02<00:01, 8922.20 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 21000/30903 [00:02<00:01, 9355.28 examples/s]Running tokenizer on train dataset:  74%|███████▍  | 23000/30903 [00:02<00:00, 9680.11 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 24000/30903 [00:02<00:00, 7949.00 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 26000/30903 [00:02<00:00, 9031.27 examples/s]Running tokenizer on train dataset:  91%|█████████ | 28000/30903 [00:03<00:00, 10037.07 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 30000/30903 [00:03<00:00, 8363.48 examples/s]                                                                                                   05/08/2023 01:07:48 - WARNING - datasets.fingerprint - Parameter 'transform'=<function main.<locals>.transform_images at 0x7f18a80ca700> of the transform datasets.arrow_dataset.Dataset.set_format couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Filter:   0%|          | 0/5118 [00:00<?, ? examples/s]Filter:  20%|█▉        | 1000/5118 [00:00<00:01, 2151.27 examples/s]Filter:  39%|███▉      | 2000/5118 [00:00<00:01, 2227.35 examples/s]Filter:  59%|█████▊    | 3000/5118 [00:01<00:01, 2092.85 examples/s]Filter:  78%|███████▊  | 4000/5118 [00:01<00:00, 2018.93 examples/s]Filter:  98%|█████████▊| 5000/5118 [00:02<00:00, 2069.30 examples/s]                                                                    Running tokenizer on validation dataset:   0%|          | 0/5118 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  20%|█▉        | 1000/5118 [00:00<00:00, 8863.16 examples/s]Running tokenizer on validation dataset:  59%|█████▊    | 3000/5118 [00:00<00:00, 11409.19 examples/s]Running tokenizer on validation dataset:  98%|█████████▊| 5000/5118 [00:00<00:00, 11229.75 examples/s]                                                                                                      Filter:   0%|          | 0/15267 [00:00<?, ? examples/s]Filter:   7%|▋         | 1000/15267 [00:00<00:07, 1920.36 examples/s]Filter:  13%|█▎        | 2000/15267 [00:01<00:06, 1972.32 examples/s]Filter:  20%|█▉        | 3000/15267 [00:01<00:06, 1936.56 examples/s]Filter:  26%|██▌       | 4000/15267 [00:02<00:05, 2002.65 examples/s]Filter:  33%|███▎      | 5000/15267 [00:02<00:04, 2056.05 examples/s]Filter:  39%|███▉      | 6000/15267 [00:02<00:04, 2047.56 examples/s]Filter:  46%|████▌     | 7000/15267 [00:03<00:04, 2024.16 examples/s]Filter:  52%|█████▏    | 8000/15267 [00:03<00:03, 1993.03 examples/s]Filter:  59%|█████▉    | 9000/15267 [00:04<00:03, 1947.30 examples/s]Filter:  66%|██████▌   | 10000/15267 [00:05<00:02, 1912.25 examples/s]Filter:  72%|███████▏  | 11000/15267 [00:05<00:02, 1918.49 examples/s]Filter:  79%|███████▊  | 12000/15267 [00:06<00:01, 1858.99 examples/s]Filter:  85%|████████▌ | 13000/15267 [00:06<00:01, 1953.60 examples/s]Filter:  92%|█████████▏| 14000/15267 [00:07<00:00, 1941.97 examples/s]Filter:  98%|█████████▊| 15000/15267 [00:07<00:00, 2024.66 examples/s]Filter: 100%|██████████| 15267/15267 [00:07<00:00, 2003.05 examples/s]                                                                      Running tokenizer on test dataset:   0%|          | 0/15267 [00:00<?, ? examples/s]Running tokenizer on test dataset:   7%|▋         | 1000/15267 [00:00<00:03, 4513.33 examples/s]Running tokenizer on test dataset:  20%|█▉        | 3000/15267 [00:00<00:01, 8061.99 examples/s]Running tokenizer on test dataset:  33%|███▎      | 5000/15267 [00:00<00:01, 9290.66 examples/s]Running tokenizer on test dataset:  46%|████▌     | 7000/15267 [00:00<00:00, 10389.45 examples/s]Running tokenizer on test dataset:  59%|█████▉    | 9000/15267 [00:01<00:00, 8870.50 examples/s] Running tokenizer on test dataset:  72%|███████▏  | 11000/15267 [00:01<00:00, 9387.52 examples/s]Running tokenizer on test dataset:  85%|████████▌ | 13000/15267 [00:01<00:00, 9876.93 examples/s]Running tokenizer on test dataset:  98%|█████████▊| 15000/15267 [00:01<00:00, 8489.20 examples/s]                                                                                                 [INFO|trainer.py:1679] 2023-05-08 01:08:03,457 >> ***** Running training *****
[INFO|trainer.py:1680] 2023-05-08 01:08:03,457 >>   Num examples = 30,903
[INFO|trainer.py:1681] 2023-05-08 01:08:03,457 >>   Num Epochs = 10
[INFO|trainer.py:1682] 2023-05-08 01:08:03,457 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1685] 2023-05-08 01:08:03,457 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
[INFO|trainer.py:1686] 2023-05-08 01:08:03,457 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1687] 2023-05-08 01:08:03,457 >>   Total optimization steps = 1,200
[INFO|trainer.py:1688] 2023-05-08 01:08:03,459 >>   Number of trainable parameters = 321,757,065
  0%|          | 0/1200 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/work/experiments/transformers/codes/run_vqa_1.py", line 732, in <module>
    main()
  File "/work/experiments/transformers/codes/run_vqa_1.py", line 671, in main
    train_result = trainer.train()
  File "/work/experiments/transformers/codes/transformers/trainer.py", line 1537, in train
    return inner_training_loop(
  File "/work/experiments/transformers/codes/transformers/trainer.py", line 1802, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/work/experiments/transformers/codes/transformers/trainer.py", line 2647, in training_step
    loss = self.compute_loss(model, inputs)
  File "/work/experiments/transformers/codes/transformers/trainer.py", line 2672, in compute_loss
    outputs = model(**inputs)
  File "/root/miniconda3/envs/transformers/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/experiments/transformers/codes/transformers/models/clip/modeling_clip.py", line 1669, in forward
    question_states = question_outputs.last_hidden_state
AttributeError: 'str' object has no attribute 'last_hidden_state'
  0%|          | 0/1200 [00:15<?, ?it/s]